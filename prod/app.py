import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
from utils import load_model, predict_character
import traceback
import os

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="Detector de Personajes de Los Simpsons",
    page_icon="ğŸŸ¡",
    layout="centered"
)

@st.cache_resource
def load_cached_model():
    """Carga el modelo y embeddings con manejo de errores mejorado"""
    try:
        model, idx_to_class = load_model('prod/modelo.pth')
        model.eval()

        # DIAGNÃ“STICO: Verificar rutas y archivos
        st.write("ğŸ” **DiagnÃ³stico de archivos:**")
        
        # Verificar directorio actual
        current_dir = os.getcwd()
        st.write(f"ğŸ“ Directorio actual: `{current_dir}`")
        
        # Verificar si existe la carpeta prod
        prod_dir = os.path.join(current_dir, 'prod')
        if os.path.exists(prod_dir):
            st.success("âœ… Directorio 'prod' encontrado")
            
            # Listar archivos en prod/
            prod_files = os.listdir(prod_dir)
            st.write("ğŸ“‹ Archivos en prod/:")
            for file in prod_files:
                file_path = os.path.join(prod_dir, file)
                file_size = os.path.getsize(file_path) if os.path.isfile(file_path) else 0
                st.write(f"  â€¢ {file} ({file_size} bytes)")
        else:
            st.error("âŒ Directorio 'prod' no encontrado")
            
            # Buscar archivos .pt en el directorio actual
            pt_files = [f for f in os.listdir('.') if f.endswith('.pt')]
            if pt_files:
                st.write("ğŸ” Archivos .pt encontrados en directorio actual:")
                for file in pt_files:
                    st.write(f"  â€¢ {file}")
        
        # Verificar archivo especÃ­fico
        embeddings_path = 'prod/reference_embeddings.pt'
        if os.path.exists(embeddings_path):
            st.success(f"âœ… Archivo {embeddings_path} encontrado")
            file_size = os.path.getsize(embeddings_path)
            st.write(f"ğŸ“Š TamaÃ±o: {file_size} bytes")
        else:
            st.error(f"âŒ Archivo {embeddings_path} NO encontrado")
            
            # Buscar archivos similares
            possible_paths = [
                'reference_embeddings.pt',
                './prod/reference_embeddings.pt',
                os.path.join(os.getcwd(), 'prod', 'reference_embeddings.pt')
            ]
            
            st.write("ğŸ” Buscando en rutas alternativas:")
            for path in possible_paths:
                if os.path.exists(path):
                    st.success(f"âœ… Encontrado en: {path}")
                    embeddings_path = path
                    break
                else:
                    st.write(f"âŒ No encontrado: {path}")

        reference_embeddings = None
        try:
            # Intentar cargar con ruta absoluta
            abs_path = os.path.abspath(embeddings_path)
            st.write(f"ğŸ”„ Intentando cargar desde: `{abs_path}`")
            
            # MÃ©todo 1: Intentar con weights_only=False (para archivos confiables)
            try:
                reference_embeddings = torch.load(embeddings_path, map_location='cpu', weights_only=False)
                st.success("âœ… Embeddings cargados con weights_only=False")
            except Exception as e1:
                st.warning(f"âš ï¸ MÃ©todo 1 fallÃ³: {str(e1)[:100]}...")
                
                # MÃ©todo 2: Intentar con safe_globals
                try:
                    import numpy as np
                    with torch.serialization.safe_globals([np.core.multiarray._reconstruct]):
                        reference_embeddings = torch.load(embeddings_path, map_location='cpu')
                    st.success("âœ… Embeddings cargados con safe_globals")
                except Exception as e2:
                    st.warning(f"âš ï¸ MÃ©todo 2 fallÃ³: {str(e2)[:100]}...")
                    
                    # MÃ©todo 3: Intentar agregar globals manualmente
                    try:
                        torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])
                        reference_embeddings = torch.load(embeddings_path, map_location='cpu')
                        st.success("âœ… Embeddings cargados con add_safe_globals")
                    except Exception as e3:
                        st.error(f"âŒ Todos los mÃ©todos fallaron. Ãšltimo error: {e3}")
                        raise e3
            
            if reference_embeddings is not None:
                st.success("âœ… Embeddings de referencia cargados correctamente")
                
                # Verificar el tipo de datos cargados
                st.write(f"ğŸ” Tipo de objeto cargado: {type(reference_embeddings)}")
                
                # Si es una tupla o lista, extraer el tensor
                if isinstance(reference_embeddings, (tuple, list)):
                    st.warning(f"âš ï¸ Se cargÃ³ una {type(reference_embeddings).__name__} con {len(reference_embeddings)} elementos")
                    for i, item in enumerate(reference_embeddings):
                        st.write(f"  Elemento {i}: {type(item)} - {getattr(item, 'shape', 'sin shape')}")
                    
                    # Intentar extraer el tensor principal
                    if len(reference_embeddings) > 0:
                        # Buscar el primer tensor en la tupla/lista
                        for item in reference_embeddings:
                            if torch.is_tensor(item):
                                reference_embeddings = item
                                st.info("âœ… Tensor extraÃ­do de la tupla/lista")
                                break
                        else:
                            st.error("âŒ No se encontrÃ³ tensor vÃ¡lido en la tupla/lista")
                            reference_embeddings = None
                
                # Verificar si ahora tenemos un tensor vÃ¡lido
                if reference_embeddings is not None and torch.is_tensor(reference_embeddings):
                    st.write(f"ğŸ“ Dimensiones: {reference_embeddings.shape}")
                    st.write(f"ğŸ“Š Tipo de datos: {reference_embeddings.dtype}")
                    st.write(f"ğŸ”¢ Rango: [{reference_embeddings.min():.4f}, {reference_embeddings.max():.4f}]")
                elif reference_embeddings is not None:
                    st.error(f"âŒ Objeto cargado no es un tensor: {type(reference_embeddings)}")
                    reference_embeddings = None
            
        except FileNotFoundError as e:
            st.error(f"âŒ Archivo no encontrado: {e}")
            st.write("ğŸ’¡ **Soluciones posibles:**")
            st.write("1. Verificar que el archivo existe en la ruta correcta")
            st.write("2. Verificar permisos de lectura del archivo")
            st.write("3. Regenerar el archivo reference_embeddings.pt")
            
        except Exception as e:
            st.error(f"âŒ Error al cargar embeddings: {e}")
            st.code(traceback.format_exc())
            st.write("ğŸ”§ **Regenerando embeddings compatibles...**")
            # Si falla la carga, generar nuevos embeddings
            try:
                reference_embeddings = generate_reference_embeddings(model, idx_to_class)
                # Guardar los nuevos embeddings
                torch.save(reference_embeddings, embeddings_path)
                st.success("âœ… Nuevos embeddings generados y guardados")
            except Exception as regen_error:
                st.error(f"âŒ Error al regenerar: {regen_error}")

        return model, idx_to_class, reference_embeddings, None
        
    except Exception as e:
        return None, None, None, f"{str(e)}\n{traceback.format_exc()}"

# FunciÃ³n alternativa para generar embeddings si no existen
def generate_reference_embeddings(model, idx_to_class):
    """Genera embeddings de referencia dummy (para pruebas)"""
    st.warning("ğŸ”§ Generando embeddings de referencia temporales...")
    
    # Crear embeddings dummy basados en las caracterÃ­sticas del modelo
    with torch.no_grad():
        # Obtener dimensiÃ³n de embedding del modelo
        dummy_input = torch.randn(1, 3, 128, 128)
        sample_embedding = model(dummy_input)
        embedding_dim = sample_embedding.shape[1]
        
        # Crear embeddings aleatorios para cada clase
        num_classes = len(idx_to_class)
        reference_embeddings = torch.randn(num_classes, embedding_dim)
        
        # Normalizar para mejorar similitud coseno
        reference_embeddings = torch.nn.functional.normalize(reference_embeddings, dim=1)
        
        st.info(f"ğŸ“ Embeddings temporales generados: {reference_embeddings.shape}")
        
        return reference_embeddings

model, idx_to_class, reference_embeddings, error_msg = load_cached_model()

# Si no hay embeddings pero sÃ­ modelo, generar temporales
if model is not None and reference_embeddings is None and error_msg is None:
    reference_embeddings = generate_reference_embeddings(model, idx_to_class)

# TransformaciÃ³n para imÃ¡genes
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# Resto de la interfaz (igual que antes)
st.title("ğŸŸ¡ Detector de Personajes de Los Simpsons")
st.markdown("### Utilizando pÃ©rdida de las trillizas (Triplet Loss)")

if error_msg:
    st.error("âŒ Error al cargar el modelo:")
    st.code(error_msg)
    st.stop()

st.info("ğŸ“ Sube una imagen de un personaje de Los Simpsons y el modelo intentarÃ¡ identificarlo.")

with st.expander("â„¹ï¸ Personajes detectables"):
    cols = st.columns(3)
    for i, name in enumerate(idx_to_class.values()):
        with cols[i % 3]:
            st.write(f"â€¢ {name.replace('_', ' ').title()}")

uploaded_file = st.file_uploader(
    "ğŸ“ SubÃ­ una imagen",
    type=["jpg", "jpeg", "png"],
    help="Formatos soportados: JPG, JPEG, PNG"
)

if uploaded_file is not None:
    try:
        image = Image.open(uploaded_file).convert("RGB")

        col1, col2 = st.columns([1, 1])
        with col1:
            st.image(image, caption="ğŸ“¸ Imagen subida", use_column_width=True)

        with col2:
            with st.spinner("ğŸ”„ Analizando imagen..."):
                tensor = transform(image).unsqueeze(0)

                if reference_embeddings is not None:
                    prediction, confidence, query_embedding = predict_character(
                        model, tensor, idx_to_class, reference_embeddings
                    )
                    if prediction != "Error en la predicciÃ³n":
                        st.success(f"ğŸ¯ **Personaje detectado:** {prediction.replace('_', ' ').title()}")
                        st.markdown(f"**Confianza:** {confidence:.3f}")
                    else:
                        st.error("âŒ Error al procesar la imagen")
                else:
                    prediction, query_embedding = predict_character(
                        model, tensor, idx_to_class, None
                    )
                    if prediction != "Error en la predicciÃ³n":
                        st.success(f"ğŸ¯ **Personaje detectado:** {prediction.replace('_', ' ').title()}")
                        st.warning("âš ï¸ MÃ©todo alternativo sin embeddings de referencia")
                    else:
                        st.error("âŒ Error al procesar la imagen")

    except Exception as e:
        st.error(f"âŒ Error al procesar la imagen: {str(e)}")
        st.code(traceback.format_exc())

st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
        Desarrollado con â¤ï¸ - Redes Neuronales Profundas - UTN FRM
    </div>
    """, unsafe_allow_html=True
)