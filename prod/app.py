import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
from utils import load_model, predict_character
import traceback
import os

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Detector de Personajes de Los Simpsons",
    page_icon="üü°",
    layout="centered"
)

@st.cache_resource
def load_cached_model():
    """Carga el modelo y embeddings con manejo de errores mejorado"""
    try:
        model, idx_to_class = load_model('prod/modelo.pth')
        model.eval()

        # DIAGN√ìSTICO: Verificar rutas y archivos
        st.write("üîç **Diagn√≥stico de archivos:**")
        
        # Verificar directorio actual
        current_dir = os.getcwd()
        st.write(f"üìÅ Directorio actual: `{current_dir}`")
        
        # Verificar si existe la carpeta prod
        prod_dir = os.path.join(current_dir, 'prod')
        if os.path.exists(prod_dir):
            st.success("‚úÖ Directorio 'prod' encontrado")
            
            # Listar archivos en prod/
            prod_files = os.listdir(prod_dir)
            st.write("üìã Archivos en prod/:")
            for file in prod_files:
                file_path = os.path.join(prod_dir, file)
                file_size = os.path.getsize(file_path) if os.path.isfile(file_path) else 0
                st.write(f"  ‚Ä¢ {file} ({file_size} bytes)")
        else:
            st.error("‚ùå Directorio 'prod' no encontrado")
            
            # Buscar archivos .pt en el directorio actual
            pt_files = [f for f in os.listdir('.') if f.endswith('.pt')]
            if pt_files:
                st.write("üîç Archivos .pt encontrados en directorio actual:")
                for file in pt_files:
                    st.write(f"  ‚Ä¢ {file}")
        
        # Verificar archivo espec√≠fico
        embeddings_path = 'prod/reference_embeddings.pt'
        if os.path.exists(embeddings_path):
            st.success(f"‚úÖ Archivo {embeddings_path} encontrado")
            file_size = os.path.getsize(embeddings_path)
            st.write(f"üìä Tama√±o: {file_size} bytes")
        else:
            st.error(f"‚ùå Archivo {embeddings_path} NO encontrado")
            
            # Buscar archivos similares
            possible_paths = [
                'reference_embeddings.pt',
                './prod/reference_embeddings.pt',
                os.path.join(os.getcwd(), 'prod', 'reference_embeddings.pt')
            ]
            
            st.write("üîç Buscando en rutas alternativas:")
            for path in possible_paths:
                if os.path.exists(path):
                    st.success(f"‚úÖ Encontrado en: {path}")
                    embeddings_path = path
                    break
                else:
                    st.write(f"‚ùå No encontrado: {path}")

        reference_embeddings = None
        try:
            # Intentar cargar con ruta absoluta
            abs_path = os.path.abspath(embeddings_path)
            st.write(f"üîÑ Intentando cargar desde: `{abs_path}`")
            
            # M√©todo 1: Intentar con weights_only=False (para archivos confiables)
            try:
                reference_embeddings = torch.load(embeddings_path, map_location='cpu', weights_only=False)
                st.success("‚úÖ Embeddings cargados con weights_only=False")
            except Exception as e1:
                st.warning(f"‚ö†Ô∏è M√©todo 1 fall√≥: {str(e1)[:100]}...")
                
                # M√©todo 2: Intentar con safe_globals
                try:
                    import numpy as np
                    with torch.serialization.safe_globals([np.core.multiarray._reconstruct]):
                        reference_embeddings = torch.load(embeddings_path, map_location='cpu')
                    st.success("‚úÖ Embeddings cargados con safe_globals")
                except Exception as e2:
                    st.warning(f"‚ö†Ô∏è M√©todo 2 fall√≥: {str(e2)[:100]}...")
                    
                    # M√©todo 3: Intentar agregar globals manualmente
                    try:
                        torch.serialization.add_safe_globals([np.core.multiarray._reconstruct])
                        reference_embeddings = torch.load(embeddings_path, map_location='cpu')
                        st.success("‚úÖ Embeddings cargados con add_safe_globals")
                    except Exception as e3:
                        st.error(f"‚ùå Todos los m√©todos fallaron. √öltimo error: {e3}")
                        raise e3
            
            if reference_embeddings is not None:
                st.success("‚úÖ Embeddings de referencia cargados correctamente")
                st.write(f"üìê Dimensiones: {reference_embeddings.shape}")
                st.write(f"üìä Tipo de datos: {reference_embeddings.dtype}")
            
        except FileNotFoundError as e:
            st.error(f"‚ùå Archivo no encontrado: {e}")
            st.write("üí° **Soluciones posibles:**")
            st.write("1. Verificar que el archivo existe en la ruta correcta")
            st.write("2. Verificar permisos de lectura del archivo")
            st.write("3. Regenerar el archivo reference_embeddings.pt")
            
        except Exception as e:
            st.error(f"‚ùå Error al cargar embeddings: {e}")
            st.code(traceback.format_exc())
            st.write("üîß **Regenerando embeddings compatibles...**")
            # Si falla la carga, generar nuevos embeddings
            try:
                reference_embeddings = generate_reference_embeddings(model, idx_to_class)
                # Guardar los nuevos embeddings
                torch.save(reference_embeddings, embeddings_path)
                st.success("‚úÖ Nuevos embeddings generados y guardados")
            except Exception as regen_error:
                st.error(f"‚ùå Error al regenerar: {regen_error}")

        return model, idx_to_class, reference_embeddings, None
        
    except Exception as e:
        return None, None, None, f"{str(e)}\n{traceback.format_exc()}"

# Funci√≥n alternativa para generar embeddings si no existen
def generate_reference_embeddings(model, idx_to_class):
    """Genera embeddings de referencia dummy (para pruebas)"""
    st.warning("üîß Generando embeddings de referencia temporales...")
    
    # Crear embeddings dummy basados en las caracter√≠sticas del modelo
    with torch.no_grad():
        # Obtener dimensi√≥n de embedding del modelo
        dummy_input = torch.randn(1, 3, 128, 128)
        sample_embedding = model(dummy_input)
        embedding_dim = sample_embedding.shape[1]
        
        # Crear embeddings aleatorios para cada clase
        num_classes = len(idx_to_class)
        reference_embeddings = torch.randn(num_classes, embedding_dim)
        
        # Normalizar para mejorar similitud coseno
        reference_embeddings = torch.nn.functional.normalize(reference_embeddings, dim=1)
        
        st.info(f"üìê Embeddings temporales generados: {reference_embeddings.shape}")
        
        return reference_embeddings

model, idx_to_class, reference_embeddings, error_msg = load_cached_model()

# Si no hay embeddings pero s√≠ modelo, generar temporales
if model is not None and reference_embeddings is None and error_msg is None:
    reference_embeddings = generate_reference_embeddings(model, idx_to_class)

# Transformaci√≥n para im√°genes
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# Resto de la interfaz (igual que antes)
st.title("üü° Detector de Personajes de Los Simpsons")
st.markdown("### Utilizando p√©rdida de las trillizas (Triplet Loss)")

if error_msg:
    st.error("‚ùå Error al cargar el modelo:")
    st.code(error_msg)
    st.stop()

st.info("üìù Sube una imagen de un personaje de Los Simpsons y el modelo intentar√° identificarlo.")

with st.expander("‚ÑπÔ∏è Personajes detectables"):
    cols = st.columns(3)
    for i, name in enumerate(idx_to_class.values()):
        with cols[i % 3]:
            st.write(f"‚Ä¢ {name.replace('_', ' ').title()}")

uploaded_file = st.file_uploader(
    "üìÅ Sub√≠ una imagen",
    type=["jpg", "jpeg", "png"],
    help="Formatos soportados: JPG, JPEG, PNG"
)

if uploaded_file is not None:
    try:
        image = Image.open(uploaded_file).convert("RGB")

        col1, col2 = st.columns([1, 1])
        with col1:
            st.image(image, caption="üì∏ Imagen subida", use_column_width=True)

        with col2:
            with st.spinner("üîÑ Analizando imagen..."):
                tensor = transform(image).unsqueeze(0)

                if reference_embeddings is not None:
                    prediction, confidence, query_embedding = predict_character(
                        model, tensor, idx_to_class, reference_embeddings
                    )
                    if prediction != "Error en la predicci√≥n":
                        st.success(f"üéØ **Personaje detectado:** {prediction.replace('_', ' ').title()}")
                        st.markdown(f"**Confianza:** {confidence:.3f}")
                    else:
                        st.error("‚ùå Error al procesar la imagen")
                else:
                    prediction, query_embedding = predict_character(
                        model, tensor, idx_to_class, None
                    )
                    if prediction != "Error en la predicci√≥n":
                        st.success(f"üéØ **Personaje detectado:** {prediction.replace('_', ' ').title()}")
                        st.warning("‚ö†Ô∏è M√©todo alternativo sin embeddings de referencia")
                    else:
                        st.error("‚ùå Error al procesar la imagen")

    except Exception as e:
        st.error(f"‚ùå Error al procesar la imagen: {str(e)}")
        st.code(traceback.format_exc())

st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
        Desarrollado con ‚ù§Ô∏è - Redes Neuronales Profundas - UTN FRM
    </div>
    """, unsafe_allow_html=True
)